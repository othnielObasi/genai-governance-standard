# Governing Generative AI in Production

This repository documents a **production-grade approach to governing Generative AI (GenAI)** — moving from high-level controls to practical implementation guidance and enforceable system design.

It is intended for:
- Engineering teams
- Security and risk leaders
- Product managers
- Auditors and reviewers
- Architects designing GenAI platforms

This work is **vendor-neutral**, **architecture-aware**, and designed to support **safe, reviewable, and auditable GenAI deployments**.


---

## Contents

- [Stage 1 — GenAI Control Catalogue](./stage-1-control-catalogue/)
- [Stage 2 — Practical Control Toolbox (Open Core)](./stage-2-toolbox/)
- [Stage 3 — Sovereign / Chain-of-Trust Architecture](./stage-3-architecture/)
- [Production Readiness Standard](./production-standard/)
  
## Relationship to OWASP and Standards
- [Relationship to OWASP](./RELATIONSHIP_TO_OWASP.md)
- [Standards Alignment (ASVS, NIST AI RMF)](./STANDARDS_ALIGNMENT.md)
- [FAQ: Why not just use OWASP?](./FAQ_OWASP.md)

---

## Scope & Positioning

This repository focuses on:
- **What must be true** for GenAI systems to be production-ready
- **How teams can implement controls in practice**
- **How systems should be architected to enforce governance**

## Out of scope
This repository focuses on baseline controls, practical artefacts, and conceptual architecture.
Tool-specific implementations, runtime enforcement logic, and operational runbooks are intentionally out of scope and must be designed and validated in accordance with organisational context and risk profile.
